{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding odd one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "v_apple = word_vectors['apple']\n",
    "v_mango = word_vectors['mango']\n",
    "\n",
    "print(v_apple.shape, v_mango.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57518554]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([v_apple], [v_mango])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    \n",
    "    all_word_vectors = [word_vectors[w] for w in words]\n",
    "    \n",
    "    avg_vector = np.mean(all_word_vectors, axis=0)\n",
    "    \n",
    "    odd_one_out = None\n",
    "    min_similarity = 1.0\n",
    "    \n",
    "    for w in words:\n",
    "        sim = cosine_similarity([word_vectors[w]], [avg_vector])\n",
    "        if sim < min_similarity:\n",
    "            min_similarity = sim\n",
    "            odd_one_out = w\n",
    "            \n",
    "        print('Similarity between %s and average vector is %.2f' %(w,sim))\n",
    "            \n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = ['apple', 'mango', 'juice', 'party', 'orange']\n",
    "input_2 = ['music', 'dance', 'sleep', 'dancer', 'food']\n",
    "input_3 = ['match', 'player', 'football', 'cricket', 'dancer']\n",
    "input_4 = ['india', 'paris', 'russia', 'france', 'germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between apple and average vector is 0.78\n",
      "Similarity between mango and average vector is 0.76\n",
      "Similarity between juice and average vector is 0.71\n",
      "Similarity between party and average vector is 0.36\n",
      "Similarity between orange and average vector is 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'party'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between music and average vector is 0.66\n",
      "Similarity between dance and average vector is 0.81\n",
      "Similarity between sleep and average vector is 0.51\n",
      "Similarity between dancer and average vector is 0.72\n",
      "Similarity between food and average vector is 0.52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between match and average vector is 0.58\n",
      "Similarity between player and average vector is 0.68\n",
      "Similarity between football and average vector is 0.72\n",
      "Similarity between cricket and average vector is 0.70\n",
      "Similarity between dancer and average vector is 0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dancer'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between india and average vector is 0.81\n",
      "Similarity between paris and average vector is 0.75\n",
      "Similarity between russia and average vector is 0.79\n",
      "Similarity between france and average vector is 0.81\n",
      "Similarity between germany and average vector is 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(a, b, c, word_vectors):\n",
    "    \n",
    "    a,b,c = a.lower(), b.lower(), c.lower()\n",
    "    \n",
    "    max_similarity = -100\n",
    "    d = None\n",
    "    \n",
    "    words = word_vectors.vocab.keys()\n",
    "    wa, wb, wc = word_vectors[a], word_vectors[b], word_vectors[c]\n",
    "    \n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa], [wv-wc])\n",
    "        \n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            d = w\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'princess'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad_1 = ('man', 'woman', 'prince')\n",
    "predict_word(*triad_1, word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Most Similar Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analogies - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    f = open(file, 'r', encoding='utf-8')\n",
    "    text = f.read()\n",
    "    \n",
    "    #Tokenization\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    data = []\n",
    "    for s in sentences:\n",
    "        words = nltk.word_tokenize(s)\n",
    "        words = [w.lower() for w in words if len(w)>2 and w not in stopw]\n",
    "        data.append(words)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['the', 'deepika', 'ranveer', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'deepika', 'ranveer', 'wedding', 'style', 'file'], ['not', 'ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'the', 'year', 'this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['priyanka', 'also', 'shared', 'video', 'featuring', 'nick', 'jonaswas', 'also', 'celebrating', 'the', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'priyanka', 'chopra', 'nick', 'jonas', 'new', 'year', 'celebrations', 'outstanding'], ['priyanka', 'chopra', 'nick', 'shared', 'glimpses', 'celebration', 'verbier', 'switzerland'], ['priyanka', 'chopra', 'married', 'nick', 'jonas', 'december', 'three', 'wedding', 'receptions', 'one', 'new', 'delhi', 'two', 'mumbai'], ['this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['kapil', 'sharma', 'ginni', 'chatrath', 'jaggo', 'night', 'december', 'made', 'even', 'special', 'industry', 'friends'], ['kapil', 'sharma', 'ginni', 'chatrath', 'friends', 'long', 'time'], ['there', 'virat', 'side', 'actress', 'wife', 'anushka', 'sharma', 'pleasure', 'audience'], ['while', 'couple', 'rang', 'new', 'year', 'style', 'morning', 'saw', 'virat', 'dress', 'squad', 'attire', 'anushka', 'pink', 'salwar', 'suit'], ['isha', 'ambani', 'married', 'anand', 'piramal', 'year']]\n"
     ]
    }
   ],
   "source": [
    "text = readFile('bollywood.txt')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=116, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(text, size=300, window=10, min_count=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018', 'the', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple', 'from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'style', 'file', 'not', 'ambanis', 'priyanka', 'nick', 'man', 'proves', 'year', 'this', 'big', 'fat', 'lavish', 'extravagant', 'weddings', 'isha', 'ambani', 'anand', 'piramal', 'chopra', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', 'saw', 'many', 'grand', 'but', 'nothing', 'beats', 'award', 'social', 'media', 'shared', 'video', 'featuring', 'jonaswas', 'celebrating', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'new', 'outstanding', 'glimpses', 'celebration', 'verbier', 'switzerland', 'married', 'december', 'three', 'receptions', 'delhi', 'mumbai', 'jaggo', 'night', 'made', 'even', 'special', 'industry', 'friends', 'long', 'time', 'there', 'virat', 'side', 'actress', 'wife', 'anushka', 'pleasure', 'audience', 'while', 'rang', 'morning', 'dress', 'squad', 'attire', 'pink', 'salwar', 'suit']\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_actor(a, b, c, word_vectors):\n",
    "    \n",
    "    a,b,c = a.lower(), b.lower(), c.lower()\n",
    "    max_similarity = -100\n",
    "    d = None\n",
    "    \n",
    "    wa,wb,wc = word_vectors[a], word_vectors[b], word_vectors[c]\n",
    "    options = ['ranveer', 'deepika', 'padukone', 'singh', 'nick', 'jonas', 'chopra', 'priyanka', 'virat', 'anushka', 'ginni']\n",
    "    \n",
    "    for w in options:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "            \n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa], [wv-wc])\n",
    "        \n",
    "        if sim>max_similarity:\n",
    "            max_similarity = sim\n",
    "            d = w\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ranveer'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = ('nick', 'priyanka', 'virat')\n",
    "predict_actor(*triad, model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'padukone'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = ('ranveer', 'deepika', 'priyanka')\n",
    "predict_actor(*triad, model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nick'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = ('ranveer', 'singh', 'deepika')\n",
    "predict_actor(*triad, model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
